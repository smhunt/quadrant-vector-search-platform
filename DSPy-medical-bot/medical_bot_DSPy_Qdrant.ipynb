{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smhunt/quadrant-vector-search-platform/blob/main/DSPy-medical-bot/medical_bot_DSPy_Qdrant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qdrant DSPy Medical Chatbot\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/qdrant/examples/blob/master/DSPy-medical-bot/medical_bot_DSPy_Qdrant.ipynb)\n",
        "\n",
        "This notebook demonstrates how to build a chatbot grounded on medical data with simple guardrails to prevent the bot from responding to non-medical questions.\n",
        "\n",
        "### Requirements\n",
        "- Qdrant\n",
        "- DSPy\n",
        "- A free [Qdrant Cloud account](https://qdrant.tech/cloud/)"
      ],
      "metadata": {
        "id": "WHRFmKAMY_Ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to install all the required packages:"
      ],
      "metadata": {
        "id": "agsIfxuTZt1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install   qdrant-client[fastembed] dspy-ai dspy-qdrant"
      ],
      "metadata": {
        "id": "LoezVqLsNrzD",
        "outputId": "e185d250-83cf-40cb-aade-34e837e606fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-3.0.4-py3-none-any.whl.metadata (285 bytes)\n",
            "Collecting dspy-qdrant\n",
            "  Downloading dspy_qdrant-0.1.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting qdrant-client[fastembed]\n",
            "  Downloading qdrant_client-1.16.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting fastembed<0.8,>=0.7 (from qdrant-client[fastembed])\n",
            "  Downloading fastembed-0.7.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client[fastembed]) (1.76.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client[fastembed]) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant-client[fastembed]) (2.0.2)\n",
            "Collecting portalocker<4.0,>=2.7.0 (from qdrant-client[fastembed])\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client[fastembed]) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant-client[fastembed]) (2.12.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client[fastembed]) (2.5.0)\n",
            "Collecting dspy>=3.0.4 (from dspy-ai)\n",
            "  Downloading dspy-3.0.4-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting backoff>=2.2 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.8.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2025.11.3)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.11.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (2.32.4)\n",
            "Collecting optuna>=3.4.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting magicattr>=0.1.6 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting litellm>=1.64.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading litellm-1.80.7-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting diskcache>=5.6.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting json-repair>=0.30.0 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading json_repair-0.54.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (9.1.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (4.11.0)\n",
            "Collecting asyncer==0.0.8 (from dspy>=3.0.4->dspy-ai)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (6.2.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.1.2)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (11.3.0)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.4->dspy-ai) (3.6.0)\n",
            "Collecting gepa==0.0.17 (from gepa[dspy]==0.0.17->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading gepa-0.0.17-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.12/dist-packages (from fastembed<0.8,>=0.7->qdrant-client[fastembed]) (0.36.0)\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed<0.8,>=0.7->qdrant-client[fastembed])\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting mmh3<6.0.0,>=4.1.0 (from fastembed<0.8,>=0.7->qdrant-client[fastembed])\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Collecting onnxruntime!=1.20.0,>=1.17.0 (from fastembed<0.8,>=0.7->qdrant-client[fastembed])\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting py-rust-stemmers<0.2.0,>=0.1.0 (from fastembed<0.8,>=0.7->qdrant-client[fastembed])\n",
            "  Downloading py_rust_stemmers-0.1.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from fastembed<0.8,>=0.7->qdrant-client[fastembed]) (0.22.1)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.41.0->qdrant-client[fastembed]) (4.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client[fastembed]) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client[fastembed]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client[fastembed]) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client[fastembed]) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.4->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client[fastembed]) (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (1.2.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.13.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.3.1)\n",
            "Collecting fastuuid>=0.13.0 (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting grpcio>=1.41.0 (from qdrant-client[fastembed])\n",
            "  Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Collecting coloredlogs (from onnxruntime!=1.20.0,>=1.17.0->fastembed<0.8,>=0.7->qdrant-client[fastembed])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (1.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.4->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.17.2)\n",
            "Collecting colorlog (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.4->dspy-ai) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.4->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.4->dspy-ai) (0.29.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.4->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.4->dspy-ai) (3.2.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed<0.8,>=0.7->qdrant-client[fastembed])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed<0.8,>=0.7->qdrant-client[fastembed]) (1.3.0)\n",
            "Downloading dspy_ai-3.0.4-py3-none-any.whl (1.1 kB)\n",
            "Downloading dspy_qdrant-0.1.3-py3-none-any.whl (4.7 kB)\n",
            "Downloading dspy-3.0.4-py3-none-any.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.2/285.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading gepa-0.0.17-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastembed-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading qdrant_client-1.16.1-py3-none-any.whl (378 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.54.2-py3-none-any.whl (29 kB)\n",
            "Downloading litellm-1.80.7-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_rust_stemmers-0.1.5-cp312-cp312-manylinux_2_28_x86_64.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastuuid-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: py-rust-stemmers, magicattr, portalocker, mmh3, loguru, json-repair, humanfriendly, grpcio, gepa, fastuuid, diskcache, colorlog, backoff, coloredlogs, asyncer, optuna, onnxruntime, qdrant-client, litellm, fastembed, dspy, dspy-qdrant, dspy-ai\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.67.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asyncer-0.0.8 backoff-2.2.1 coloredlogs-15.0.1 colorlog-6.10.1 diskcache-5.6.3 dspy-3.0.4 dspy-ai-3.0.4 dspy-qdrant-0.1.3 fastembed-0.7.3 fastuuid-0.14.0 gepa-0.0.17 grpcio-1.67.1 humanfriendly-10.0 json-repair-0.54.2 litellm-1.80.7 loguru-0.7.3 magicattr-0.1.6 mmh3-5.2.0 onnxruntime-1.23.2 optuna-4.6.0 portalocker-3.2.0 py-rust-stemmers-0.1.5 qdrant-client-1.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U datasets"
      ],
      "metadata": {
        "id": "bOrkeclKRaSN",
        "outputId": "2764ca6f-4f22-4265-bf6d-8b9f97704100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.1 pyarrow-22.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the modules needed for this project."
      ],
      "metadata": {
        "id": "UG-AFODUZyoM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "35OXFPOUNULU"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from qdrant_client import QdrantClient, models\n",
        "from google.colab import userdata\n",
        "import dspy\n",
        "from dspy_qdrant import QdrantRM\n",
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.models import Filter, FieldCondition, MatchValue"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Qdrant Cloud"
      ],
      "metadata": {
        "id": "6D03oK0SOIW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain your Qdrant API key and URL from the Qdrant Cloud dashboard and save them as secrets on Colab. If running locally, create a `.env` file and save them there, then modify the part below accordingly."
      ],
      "metadata": {
        "id": "DSmUC0goZ5FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = QdrantClient(\n",
        "    url=userdata.get(\"QDRANT_CLOUD_URL\"),\n",
        "    api_key=userdata.get(\"QDRANT_API_KEY\"),\n",
        "    timeout=60.0,\n",
        "    prefer_grpc=True\n",
        ")"
      ],
      "metadata": {
        "id": "sdSDdeiWNXWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load MIRIAD dataset (sample for demo)"
      ],
      "metadata": {
        "id": "G-OgirC-PP80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we load a sample of the Miriad medical dataset. You can also modify this to use the [entire dataset](https://huggingface.co/datasets/miriad/miriad-5.8M), but uploading the vectors will take longer. Colab also doesn't provide enough resources to store the entire downloaded dataset."
      ],
      "metadata": {
        "id": "4q4tod0iaPar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"mwitiderrick/miriad-1k\", split=\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g1PSWoaOXYu",
        "outputId": "fed75db2-48a3-4ad2-9f1a-4140072ddcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate embeddings\n",
        "\n",
        "Next, encode the medical data:"
      ],
      "metadata": {
        "id": "eG_i-BQyPVzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_documents = [\n",
        "    models.Document(text=doc, model=\"BAAI/bge-small-en\")\n",
        "    for doc in ds['passage_text']\n",
        "]\n",
        "\n",
        "colbert_documents = [\n",
        "    models.Document(text=doc, model=\"colbert-ir/colbertv2.0\")\n",
        "    for doc in ds['passage_text']\n",
        "]"
      ],
      "metadata": {
        "id": "oRmGpeZGPQbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create collection"
      ],
      "metadata": {
        "id": "iE1XwwR2PhYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then create a Qdrant collection with the dense and colbert vectors. Note that we leave indexing on for the dense vector but turn it off for the colbert vector that will be used for reranking. Checkout the [How to Effectively Use Multivector Representations](https://qdrant.tech/documentation/advanced-tutorials/using-multivector-representations/) in Qdrant for Reranking tutorial to learn more about this.\n"
      ],
      "metadata": {
        "id": "YNgOpCK-bPNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"medical_chat_bot\"\n",
        "\n",
        "if not client.collection_exists(collection_name):\n",
        "    client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config={\n",
        "            \"dense\": models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
        "            \"colbert\": models.VectorParams(\n",
        "                size=128,\n",
        "                distance=models.Distance.COSINE,\n",
        "                multivector_config=models.MultiVectorConfig(\n",
        "                    comparator=models.MultiVectorComparator.MAX_SIM\n",
        "                ),\n",
        "                hnsw_config=models.HnswConfigDiff(m=0)  # reranker: no indexing\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Create payload indexes\n",
        "    client.create_payload_index(\n",
        "        collection_name=collection_name,\n",
        "        field_name=\"specialty\",\n",
        "        field_schema=\"keyword\",\n",
        "    )\n",
        "\n",
        "    client.create_payload_index(\n",
        "        collection_name=collection_name,\n",
        "        field_name=\"year\",\n",
        "        field_schema=\"integer\",\n",
        "    )"
      ],
      "metadata": {
        "id": "mm8cPC2NPflZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create indexes from the `specialty` and `year` columns since we will be filtering the responses from the vector database using them. Adding the payload indexes speeds up filtering. Checkout our [Indexing guide](https://qdrant.tech/documentation/concepts/indexing/) to learn more."
      ],
      "metadata": {
        "id": "_mp-0vSfe-46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch upload in chunks"
      ],
      "metadata": {
        "id": "tuy_yBsAPobO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ColBERT produces ~1k vectors per point, so we will batch upload the vectors to avoid hitting API limits."
      ],
      "metadata": {
        "id": "CTeqxT50bZv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 3\n",
        "points_batch = []\n",
        "\n",
        "for i in range(len(ds['passage_text'])):\n",
        "    point = models.PointStruct(\n",
        "        id=i,\n",
        "        vector={\n",
        "            \"dense\": dense_documents[i],\n",
        "            \"colbert\": colbert_documents[i]\n",
        "        },\n",
        "        payload={\n",
        "        \"passage_text\": ds['passage_text'][i],\n",
        "         \"year\": ds['year'][i],\n",
        "         \"specialty\": ds['specialty'][i],\n",
        "         }\n",
        "    )\n",
        "    points_batch.append(point)\n",
        "\n",
        "    if len(points_batch) == BATCH_SIZE:\n",
        "        client.upsert(collection_name=collection_name, points=points_batch)\n",
        "        print(f\"Uploaded batch ending at index {i}\")\n",
        "        points_batch = []\n",
        "\n",
        "# Final flush\n",
        "if points_batch:\n",
        "    client.upsert(collection_name=collection_name, points=points_batch)\n",
        "    print(\"Uploaded final batch.\")"
      ],
      "metadata": {
        "id": "4VpJVAu3PkZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSPy setup"
      ],
      "metadata": {
        "id": "0zWqy9hDP-zO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, setup [DSPy and Qdrant](https://qdrant.tech/documentation/frameworks/dspy/) to work together."
      ],
      "metadata": {
        "id": "-4o09M8rcQOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm = dspy.LM(\"gpt-4\", max_tokens=512,api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "client = QdrantClient(url=userdata.get(\"QDRANT_CLOUD_URL\"), api_key=userdata.get(\"QDRANT_API_KEY\"))"
      ],
      "metadata": {
        "id": "5ue65kMiP6KX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup QdrantRM"
      ],
      "metadata": {
        "id": "wqPEH7WFQFjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QdrantRM is a retrieval module that uses Qdrant to return the top passages for a given query. DSPy can then use these passages to provide the best response.\n",
        "\n"
      ],
      "metadata": {
        "id": "_ZvGvgDich_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rm = QdrantRM(\n",
        "    qdrant_collection_name=collection_name,\n",
        "    qdrant_client=client,\n",
        "    vector_name=\"dense\",                 # <-- MATCHES your vector field in upsert\n",
        "    document_field=\"passage_text\",        # <-- MATCHES your payload field in upsert\n",
        "    k=20)\n",
        "\n",
        "dspy.settings.configure(lm=lm, rm=rm)"
      ],
      "metadata": {
        "id": "2Y_WvEJKP_83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual reranker using Qdrant’s native prefetch + ColBERT query"
      ],
      "metadata": {
        "id": "TqJTT83bQOKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we define a function using Qdrant's multi-vector search capabilities with both dense and late-interaction (ColBERT-style) embeddings for retrieval and reranking.\n",
        "\n",
        "We also include filtering by year and speciality. This way one can filter results for a specific speciality and within a certain year range. This is important for getting the most recent information. Checkout our [Filtering guide](https://qdrant.tech/documentation/concepts/filtering/) to learn more about filtering data from Qdrant."
      ],
      "metadata": {
        "id": "llXNL3EVc2dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rerank_with_colbert(query_text, min_year, max_year, specialty):\n",
        "    from fastembed import TextEmbedding, LateInteractionTextEmbedding\n",
        "\n",
        "    # Encode query once with both models\n",
        "    dense_model = TextEmbedding(\"BAAI/bge-small-en\")\n",
        "    colbert_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")\n",
        "\n",
        "    dense_query = list(dense_model.embed(query_text))[0]\n",
        "    colbert_query = list(colbert_model.embed(query_text))[0]\n",
        "\n",
        "    # Combined query: retrieve with dense, rerank with ColBERT\n",
        "    results = client.query_points(\n",
        "        collection_name=collection_name,\n",
        "        prefetch=models.Prefetch(\n",
        "            query=dense_query,\n",
        "            using=\"dense\"\n",
        "        ),\n",
        "        query=colbert_query,\n",
        "        using=\"colbert\",\n",
        "        limit=5,\n",
        "        with_payload=True,\n",
        "        query_filter=Filter(\n",
        "            must=[\n",
        "                FieldCondition(key=\"specialty\", match=MatchValue(value=specialty)),\n",
        "                FieldCondition(key=\"year\",range=models.Range(gt=None,gte=min_year,lt=None,lte=max_year))\n",
        "            ]\n",
        "\n",
        "        )\n",
        "    )\n",
        "\n",
        "    points = results.points\n",
        "    docs = []\n",
        "\n",
        "    for point in points:\n",
        "        docs.append(point.payload['passage_text'])\n",
        "\n",
        "    return docs\n"
      ],
      "metadata": {
        "id": "OPad4jxgQHV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSPy Signature and Module"
      ],
      "metadata": {
        "id": "3NrURTn-QWOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a DSPy signature:"
      ],
      "metadata": {
        "id": "MqirB3gOdtWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalAnswer(dspy.Signature):\n",
        "    question = dspy.InputField(desc=\"The medical question to answer\")\n",
        "    is_medical = dspy.OutputField(desc=\"Answer 'Yes' if the question is medical, otherwise 'No'\")\n",
        "    min_year = dspy.InputField(desc=\"The minimum year of the medical paper\")\n",
        "    max_year = dspy.InputField(desc=\"The maximum year of the medical paper\")\n",
        "    specialty = dspy.InputField(desc=\"The specialty of the medical paper\")\n",
        "    context = dspy.OutputField(desc=\"The answer to the medical question\")\n",
        "    final_answer = dspy.OutputField(desc=\"The answer to the medical question\")\n"
      ],
      "metadata": {
        "id": "7OFI4KIbQQpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Guardrail"
      ],
      "metadata": {
        "id": "2mgX1pmTQa4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup a simple guardrail to ensure the system doesn't respond to non-medical questions."
      ],
      "metadata": {
        "id": "p2tTwXRsdwiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalGuardrail(dspy.Module):\n",
        "    def forward(self, question):\n",
        "        prompt = (\n",
        "            \"Is the following question a medical question? Answer with 'Yes' or 'No'.\\n\"\n",
        "            f\"Question: {question}\\n\"\n",
        "            \"Answer:\"\n",
        "        )\n",
        "        response = dspy.settings.lm(prompt)\n",
        "        answer = response[0].strip().lower()\n",
        "        return answer.startswith(\"yes\")"
      ],
      "metadata": {
        "id": "TDmWEpg9QXfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure MedicalRAG"
      ],
      "metadata": {
        "id": "0f9dNaE5QhAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the medical RAG with chain of thought reasoning:"
      ],
      "metadata": {
        "id": "IL3GzPJkd4wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MedicalRAG(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.guardrail = MedicalGuardrail()\n",
        "\n",
        "    def forward(self, question, min_year, max_year, specialty):\n",
        "        if not self.guardrail.forward(question):\n",
        "            class DummyResult:\n",
        "                final_answer = \"Sorry, I can only answer medical questions. Please ask a question related to medicine or healthcare.\"\n",
        "            return DummyResult()\n",
        "        reranked_docs = rerank_with_colbert(question, min_year, max_year, specialty)\n",
        "        context_str = \"\\n\".join(reranked_docs)\n",
        "        return dspy.ChainOfThought(MedicalAnswer)(\n",
        "            question=question,\n",
        "            min_year=min_year,\n",
        "            max_year=max_year,\n",
        "            specialty=specialty,\n",
        "            context=context_str\n",
        "        )\n"
      ],
      "metadata": {
        "id": "5g72tR0rQc38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Sample Question"
      ],
      "metadata": {
        "id": "MilYURA5Qp97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define some sample questions:"
      ],
      "metadata": {
        "id": "iM1XcOQxd_mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_questions = [\n",
        "    \"What are the most common symptoms of lupus?\",\n",
        "    \"How is type 2 diabetes usually managed in adults?\",\n",
        "    \"What are the first-line medications for treating hypertension?\",\n",
        "]"
      ],
      "metadata": {
        "id": "-BmOlJ4mQgAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List all the specialities in the dataset for reference:"
      ],
      "metadata": {
        "id": "XQ0M9igheC8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specialty_options = [\n",
        "                \"Rheumatology\", \"Psychiatry\", \"Pulmonology & Respiratory Medicine\", \"Nephrology\", \"Public Health & Epidemiology\",\n",
        "                \"Medical Research & Methodology\", \"Pharmacy & Pharmacology\", \"Hematology\", \"Oncology\", \"Medical Ethics & Law\",\n",
        "                \"Medical Technology & Informatics\", \"Infectious Disease\", \"Basic Medical Sciences\", \"Allergology\", \"Geriatrics\",\n",
        "                \"Cardiology\", \"Gastroenterology & Hepatology\", \"General Surgery\", \"General Pediatrics\", \"Endocrinology & Metabolism\",\n",
        "                \"Vascular Surgery\", \"Radiology & Imaging\", \"Obstetrics & Gynecology\", \"Orthopedic Surgery\", \"Neurology\",\n",
        "                \"Family Medicine & Primary Care\", \"Psychology & Behavioral Health\", \"Otorhinolaryngology (ENT)\", \"General Internal Medicine\",\n",
        "                \"Anesthesiology\", \"Physical & Rehabilitation Medicine\", \"Medical Education\", \"Healthcare Administration & Management\",\n",
        "                \"Non-Medical Sciences & Disciplines\", \"Dermatology\", \"Critical Care & Intensive Care\", \"Urology\", \"Complementary & Alternative Medicine\",\n",
        "                \"Cardiothoracic Surgery\", \"Neurosurgery\", \"Pediatric Subspecialties\", \"Occupational & Environmental Health\", \"Ophthalmology\",\n",
        "                \"Emergency Medicine\", \"Dental & Oral Medicine\", \"Biomedical Engineering\", \"Pathology & Laboratory Medicine\", \"Transplant Surgery\",\n",
        "                \"Preventive Medicine\", \"Genetics\", \"Nursing\", \"Allied Health Professions\", \"Plastic & Reconstructive Surgery\", \"Others\",\n",
        "                \"Toxicology\", \"General Medicine\"\n",
        "            ]"
      ],
      "metadata": {
        "id": "MM_9ItaOQ8a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the medical RAG with a sample question:"
      ],
      "metadata": {
        "id": "QuSaSZ3leHjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = MedicalRAG()\n",
        "min_year = 1990\n",
        "max_year = 2021\n",
        "specialty = specialty_options[0]\n",
        "result = rag_chain.forward(sample_questions[0], min_year, max_year, specialty)"
      ],
      "metadata": {
        "id": "dxbSdQfJQroG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.reasoning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk93KQDbWfY1",
        "outputId": "c8e4fc95-f310-4697-ff59-3ce0868ebfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question is asking for the most common symptoms of a specific medical condition, lupus, which falls under the specialty of Rheumatology. Therefore, the question is medical in nature and requires a response based on medical knowledge and research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.is_medical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8nngUOgWfWR",
        "outputId": "c5cc5e08-d1c7-4b90-f44f-e19c9dc42819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLfDY4RgWjr0",
        "outputId": "d4019e21-f589-4b14-ac43-30543a9c8217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most common symptoms of lupus are fatigue, joint pain and swelling, skin rashes (particularly a butterfly-shaped rash across the cheeks and nose), fever, chest pain, hair loss, mouth sores, sensitivity to sunlight, and swollen lymph nodes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the medical RAG application with a non-medical question:"
      ],
      "metadata": {
        "id": "K6j8CehEeN5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = rag_chain.forward(\"How is the weather today?\", min_year, max_year, specialty)"
      ],
      "metadata": {
        "id": "NRWfZQreWmUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpLyndoyWvKx",
        "outputId": "ec1e7048-cee9-43c3-c457-a17f6151c364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I can only answer medical questions. Please ask a question related to medicine or healthcare.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "Multivector search is one of the most powerful features for building a medical RAG application. With this functionality in Qdrant, you can:\n",
        "\n",
        "- Store token-level embeddings natively. Disable indexing to reduce overhead.\n",
        "\n",
        "- Run fast retrieval and accurate reranking in one API call.\n",
        "\n",
        "- Efficiently scale late interaction. Combining FastEmbed and Qdrant leads to a production-ready pipeline for ColBERT-style reranking without wasting resources.\n",
        "\n",
        " You can do this locally or use Qdrant Cloud. Qdrant offers an easy-to-use API to get started with your search engine, so if you’re ready to dive in, sign up for free at [Qdrant Cloud](https://qdrant.tech/documentation/cloud-intro/) and start building."
      ],
      "metadata": {
        "id": "PvpA1_tIeYKo"
      }
    }
  ]
}